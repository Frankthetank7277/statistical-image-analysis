<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Convolution Theory Walkthrough</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            overflow: hidden;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
        }

        header p {
            font-size: 1.1em;
            opacity: 0.9;
        }

        .content {
            padding: 40px;
        }

        section {
            margin-bottom: 50px;
        }

        h2 {
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #667eea;
        }

        h3 {
            color: #764ba2;
            font-size: 1.3em;
            margin: 25px 0 15px 0;
        }

        p {
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .math-block {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 4px solid #667eea;
            overflow-x: auto;
        }

        .visual-demo {
            background: #f0f4ff;
            padding: 30px;
            border-radius: 8px;
            margin: 25px 0;
            border: 2px solid #667eea;
        }

        .signal-display {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 20px;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        .signal-box {
            background: white;
            padding: 15px;
            border-radius: 6px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .signal-label {
            font-weight: 600;
            color: #764ba2;
            margin-bottom: 8px;
            text-align: center;
        }

        .signal-values {
            display: flex;
            gap: 8px;
        }

        .value-cell {
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
            background: #667eea;
            color: white;
            border-radius: 4px;
            font-weight: 600;
        }

        .kernel-cell {
            background: #764ba2;
        }

        .result-cell {
            background: #48bb78;
        }

        code {
            background: #f1f3f5;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #c7254e;
        }

        pre {
            background: #282c34;
            color: #abb2bf;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            line-height: 1.5;
        }

        pre code {
            background: none;
            color: inherit;
            padding: 0;
        }

        .keyword { color: #c678dd; }
        .string { color: #98c379; }
        .comment { color: #5c6370; font-style: italic; }
        .function { color: #61afef; }
        .number { color: #d19a66; }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            border-radius: 8px;
            overflow: hidden;
        }

        th, td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #e9ecef;
        }

        th {
            background: #667eea;
            color: white;
            font-weight: 600;
        }

        tr:last-child td {
            border-bottom: none;
        }

        tr:hover {
            background: #f8f9fa;
        }

        .highlight-box {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .highlight-box strong {
            color: #856404;
        }

        .interactive-section {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 30px;
            border-radius: 8px;
            margin: 25px 0;
        }

        .steps-list {
            list-style: none;
            counter-reset: step-counter;
        }

        .steps-list li {
            counter-increment: step-counter;
            margin-bottom: 20px;
            padding-left: 50px;
            position: relative;
        }

        .steps-list li::before {
            content: counter(step-counter);
            position: absolute;
            left: 0;
            top: 0;
            background: #667eea;
            color: white;
            width: 35px;
            height: 35px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 700;
        }

        .key-takeaway {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 8px;
            margin: 30px 0;
        }

        .key-takeaway h3 {
            color: white;
            margin-top: 0;
        }

        ul:not(.steps-list) {
            margin-left: 30px;
            margin-bottom: 15px;
        }

        ul:not(.steps-list) li {
            margin-bottom: 8px;
        }

        .canvas-container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            text-align: center;
        }

        canvas {
            border: 2px solid #667eea;
            border-radius: 4px;
            max-width: 100%;
        }

        @media (max-width: 768px) {
            .content {
                padding: 20px;
            }

            header h1 {
                font-size: 1.8em;
            }

            .signal-display {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Convolution Theory Walkthrough</h1>
            <p>From fundamentals to CNNs: Understanding the most important operation in signal processing and deep learning</p>
        </header>

        <div class="content">
            <section id="intro">
                <h2>What Is Convolution, Really?</h2>
                <p>At its core, convolution answers the question: <strong>how much do two functions overlap as one slides over the other?</strong></p>
                
                <div class="math-block">
                    <p><strong>Continuous form:</strong></p>
                    <p>\[(f * g)(t) = \int_{-\infty}^{\infty} f(\tau) \cdot g(t - \tau) \, d\tau\]</p>
                </div>

                <div class="math-block">
                    <p><strong>Discrete form (more relevant for computational work):</strong></p>
                    <p>\[(f * g)[n] = \sum_{k=-\infty}^{\infty} f[k] \cdot g[n - k]\]</p>
                </div>

                <div class="highlight-box">
                    <p><strong>Three key operations hidden in that formula:</strong></p>
                    <ol class="steps-list">
                        <li><strong>Flip</strong> — \(g(\tau)\) becomes \(g(-\tau)\), reversing the kernel</li>
                        <li><strong>Shift</strong> — controlled by \(t\) (or \(n\)), sliding the flipped kernel across the signal</li>
                        <li><strong>Multiply and sum</strong> — the dot product at each position</li>
                    </ol>
                </div>
            </section>

            <section id="intuition">
                <h2>Building Intuition: The Sliding Window</h2>
                <p>Think of a 1D example. Say you have a signal \(f\) and a kernel \(g\):</p>

                <div class="visual-demo">
                    <div class="signal-display">
                        <div class="signal-box">
                            <div class="signal-label">Signal f</div>
                            <div class="signal-values">
                                <div class="value-cell">1</div>
                                <div class="value-cell">2</div>
                                <div class="value-cell">3</div>
                                <div class="value-cell">4</div>
                                <div class="value-cell">5</div>
                            </div>
                        </div>

                        <div class="signal-box">
                            <div class="signal-label">Kernel g (averaging)</div>
                            <div class="signal-values">
                                <div class="value-cell kernel-cell">0.5</div>
                                <div class="value-cell kernel-cell">0.5</div>
                            </div>
                        </div>
                    </div>

                    <p style="margin-top: 20px; text-align: center;">At each position \(n\), you flip \(g\), align it with \(f\), multiply element-wise, and sum.</p>
                </div>

                <p>This simple averaging kernel is a <strong>low-pass filter</strong>: it suppresses rapid changes and preserves slow trends.</p>

                <div class="visual-demo">
                    <p><strong>Example computation at position n=1:</strong></p>
                    <p style="text-align: center; font-family: monospace; font-size: 1.1em; margin-top: 15px;">
                        (f * g)[1] = f[0]·g[1] + f[1]·g[0] = 1×0.5 + 2×0.5 = <strong style="color: #48bb78;">1.5</strong>
                    </p>
                </div>

                <p>Change the kernel to <code>[-1, 1]</code> and you're computing differences between neighbors — a <strong>high-pass filter</strong> that detects edges.</p>

                <div class="key-takeaway">
                    <h3>Key Insight</h3>
                    <p>The kernel <em>encodes what structure you care about</em>. Different kernels extract different features from your signal.</p>
                </div>
            </section>

            <section id="2d">
                <h2>2D Convolution: Images</h2>
                <p>For images, the operation extends to two dimensions:</p>

                <div class="math-block">
                    <p>\[(f * g)[m, n] = \sum_j \sum_k f[j, k] \cdot g[m - j, n - k]\]</p>
                </div>

                <p>You slide a 2D kernel (patch) over the image, computing a weighted sum at each location. The output is called a <strong>feature map</strong>.</p>

                <h3>Classic Kernel Examples</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Kernel Type</th>
                            <th>Effect</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>All equal weights (box filter)</td>
                            <td>Blurring (low-pass filter)</td>
                        </tr>
                        <tr>
                            <td>Laplacian</td>
                            <td>Edge detection</td>
                        </tr>
                        <tr>
                            <td>Sobel (horizontal)</td>
                            <td>Horizontal gradient detection</td>
                        </tr>
                        <tr>
                            <td>Gaussian</td>
                            <td>Smooth blur with natural falloff</td>
                        </tr>
                    </tbody>
                </table>

                <div class="canvas-container">
                    <h4 style="margin-bottom: 15px;">Example: 3×3 Sobel Kernel (Horizontal)</h4>
                    <canvas id="kernelCanvas" width="200" height="200"></canvas>
                </div>

                <p>This connects directly to your DFT work in BIOE 484 — convolution in the spatial domain is equivalent to <strong>multiplication in the frequency domain</strong> (the convolution theorem). That's why filtering is often done in Fourier space: it's faster and conceptually clean.</p>
            </section>

            <section id="theorem">
                <h2>The Convolution Theorem</h2>
                
                <div class="math-block">
                    <p>\[\mathcal{F}\{f * g\} = \mathcal{F}\{f\} \cdot \mathcal{F}\{g\}\]</p>
                </div>

                <p><strong>Convolution in the spatial domain ↔ pointwise multiplication in the frequency domain.</strong></p>

                <div class="highlight-box">
                    <p><strong>This is why:</strong></p>
                    <ul>
                        <li>A <strong>Gaussian filter</strong> attenuates high frequencies (its Fourier transform is also a Gaussian, centered at zero)</li>
                        <li>A <strong>box filter</strong> has ringing artifacts (its Fourier transform is a sinc function with side lobes)</li>
                        <li><strong>Edge detection kernels</strong> amplify high frequencies</li>
                    </ul>
                </div>

                <div class="interactive-section">
                    <h3>Practical Implication</h3>
                    <p>For large images or kernels, it's often faster to:</p>
                    <ol class="steps-list">
                        <li>Take the FFT of both the image and kernel</li>
                        <li>Multiply them element-wise in frequency domain</li>
                        <li>Take the inverse FFT to get back the convolved result</li>
                    </ol>
                    <p style="margin-top: 20px;">This is especially relevant when working with your brain MRI images!</p>
                </div>
            </section>

            <section id="cnns">
                <h2>Convolution in CNNs</h2>
                <p>This is where it gets directly relevant to your deep learning coursework. In a convolutional neural network:</p>

                <ul>
                    <li>The kernels are <strong>learned</strong>, not hand-designed</li>
                    <li>Each kernel learns to respond to a specific feature (edge, texture, curve, etc.)</li>
                    <li>Stacking layers lets the network build hierarchical representations: edges → shapes → objects</li>
                </ul>

                <h3>Important Implementation Notes</h3>

                <div class="highlight-box">
                    <p><strong>Cross-correlation vs. true convolution:</strong></p>
                    <p>Most deep learning frameworks (including PyTorch's <code>nn.Conv2d</code>) actually compute <em>cross-correlation</em>, which skips the flipping step:</p>
                    <div class="math-block" style="background: white; margin-top: 10px;">
                        <p>\[(f \star g)[m, n] = \sum_j \sum_k f[m + j, n + k] \cdot g[j, k]\]</p>
                    </div>
                    <p>Since kernels are learned anyway, the flip is absorbed into the learned weights. The distinction matters mathematically but not practically in training.</p>
                </div>

                <div class="visual-demo">
                    <p><strong>Key Hyperparameters:</strong></p>
                    <ul>
                        <li><strong>Padding</strong> — controls what happens at borders. <code>padding='same'</code> preserves spatial dimensions, <code>padding='valid'</code> shrinks them</li>
                        <li><strong>Stride</strong> — controls step size. Stride 2 roughly halves spatial dimensions and is a common alternative to pooling for downsampling</li>
                    </ul>
                </div>
            </section>

            <section id="code">
                <h2>Putting It Together: PyTorch Example</h2>
                <p>Here's a minimal PyTorch example to make it concrete:</p>

                <pre><code><span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn

<span class="comment"># A single conv layer: 1 input channel, 1 output channel, 3x3 kernel</span>
conv = nn.<span class="function">Conv2d</span>(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)

<span class="comment"># Manually set kernel to a horizontal edge detector (Sobel-like)</span>
<span class="keyword">with</span> torch.<span class="function">no_grad</span>():
    conv.weight[<span class="number">0</span>, <span class="number">0</span>] = torch.<span class="function">tensor</span>([
        [<span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-1.</span>],
        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],
        [ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">1.</span>]
    ])
    conv.bias[<span class="number">0</span>] = <span class="number">0.</span>

<span class="comment"># Apply to a dummy image</span>
img = torch.<span class="function">rand</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>)  <span class="comment"># batch=1, channels=1, 8x8</span>
output = <span class="function">conv</span>(img)
<span class="function">print</span>(output.shape)  <span class="comment"># → torch.Size([1, 1, 8, 8])</span></code></pre>

                <p>In a real CNN, those kernel weights would be initialized randomly and updated via backpropagation — the same chain rule mechanics you've been working through.</p>
            </section>

            <section id="takeaways">
                <h2>Key Takeaways</h2>
                
                <div class="key-takeaway">
                    <h3>Core Properties of Convolution</h3>
                    <p>Convolution is a <strong>local, translation-equivariant</strong> operation. If a feature appears anywhere in the image, the same kernel will detect it — that's the power of weight sharing.</p>
                    <p style="margin-top: 15px;">Combined with learned kernels and deep stacking, it's why CNNs work so well on spatial data like your brain MRI images.</p>
                </div>

                <div class="highlight-box">
                    <p><strong>The Mathematical Journey:</strong></p>
                    <ul>
                        <li>Convolution measures overlap between functions</li>
                        <li>In frequency domain, convolution becomes multiplication (convolution theorem)</li>
                        <li>In CNNs, kernels are learned features that build hierarchical representations</li>
                        <li>Backpropagation optimizes these kernels for your specific task</li>
                    </ul>
                </div>

                <div class="interactive-section">
                    <h3>Applications to Your Work</h3>
                    <ul>
                        <li><strong>BIOE 484:</strong> Your 2D DFT work on brain MRI directly connects to the convolution theorem</li>
                        <li><strong>Deep Learning:</strong> CNNs for CIFAR-10 and beyond use these same principles</li>
                        <li><strong>Spatial Biology:</strong> Convolution operations can help analyze tumor microenvironments in tissue images</li>
                    </ul>
                </div>
            </section>

            <section id="next">
                <h2>Want to Go Deeper?</h2>
                <p>We can explore:</p>
                <ul>
                    <li>The frequency domain connection in more detail</li>
                    <li>Backpropagation through convolutional layers</li>
                    <li>How this connects to your 2D DFT assignments</li>
                    <li>Advanced architectures (dilated convolutions, separable convolutions, etc.)</li>
                    <li>Practical implementation tips for your coursework</li>
                </ul>
            </section>
        </div>
    </div>

    <script>
        // Draw Sobel kernel visualization
        const canvas = document.getElementById('kernelCanvas');
        const ctx = canvas.getContext('2d');
        
        const kernel = [
            [-1, -2, -1],
            [0, 0, 0],
            [1, 2, 1]
        ];
        
        const cellSize = 60;
        const startX = 10;
        const startY = 10;
        
        for (let i = 0; i < 3; i++) {
            for (let j = 0; j < 3; j++) {
                const value = kernel[i][j];
                const x = startX + j * cellSize;
                const y = startY + i * cellSize;
                
                // Color based on value
                if (value < 0) {
                    ctx.fillStyle = '#764ba2';
                } else if (value > 0) {
                    ctx.fillStyle = '#667eea';
                } else {
                    ctx.fillStyle = '#e9ecef';
                }
                
                ctx.fillRect(x, y, cellSize, cellSize);
                ctx.strokeStyle = '#333';
                ctx.lineWidth = 2;
                ctx.strokeRect(x, y, cellSize, cellSize);
                
                // Draw value
                ctx.fillStyle = value === 0 ? '#333' : 'white';
                ctx.font = 'bold 20px Arial';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'middle';
                ctx.fillText(value, x + cellSize/2, y + cellSize/2);
            }
        }
    </script>
</body>
</html>